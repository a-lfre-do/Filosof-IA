# ğŸ§ª Ã‰tica y Responsabilidad en IA

El uso de modelos de lenguaje en educaciÃ³n no es solo una cuestiÃ³n tÃ©cnica: plantea preguntas Ã©ticas sobre la autonomÃ­a, la veracidad, la equidad y la responsabilidad. Esta pÃ¡gina sintetiza los principales enfoques y recomendaciones para integrar la IA de forma responsable en el aula.
## ğŸ§‘â€ğŸ“ Dimensiones Ã©ticas

1. Veracidad y fiabilidad. Los LLM pueden generar respuestas plausibles pero incorrectas (alucinaciones). Por ello, se aconseja contrastar sus afirmaciones con fuentes confiables y enseÃ±ar a los estudiantes a cuestionar la veracidad de la informaciÃ³n que reciben.
2. Equidad y no discriminaciÃ³n. Los modelos aprenden de datos que pueden contener sesgos. Debemos diseÃ±ar prompts y actividades que incluyan diversas perspectivas, y promover la reflexiÃ³n sobre cÃ³mo los prejuicios se introducen en la IA.
3. Privacidad y consentimiento. No se deben introducir datos personales o sensibles. Las herramientas utilizadas deben cumplir con marcos legales como el AIÂ BillÂ ofÂ Rights y la Ley de IA de la UE, que exigen limitar la recolecciÃ³n de datos y proporcionar alternativas humanas .
4. Transparencia. Los estudiantes tienen derecho a saber cuÃ¡ndo se emplea IA y cÃ³mo influye en el proceso educativo. Explica siempre la funciÃ³n de la IA y las limitaciones de sus respuestas .
5. AutonomÃ­a y desarrollo del juicio. La IA debe ser un recurso para estimular el pensamiento crÃ­tico, no un sustituto del razonamiento. Las tareas deben incentivar que los alumnos elaboren sus propios argumentos y usen la IA como apoyo.

## ğŸ“Œ Recomendaciones prÃ¡cticas

- Crea un acuerdo de uso. En cada curso, redacta con tu clase unas normas sobre cÃ³mo, cuÃ¡ndo y por quÃ© se usarÃ¡ la IA. Incluye clÃ¡usulas de consentimiento y uso responsable.
- Fomenta la reflexiÃ³n metacognitiva. Tras interactuar con la IA, pide a los estudiantes que identifiquen quÃ© aprendieron, quÃ© errores detectaron y quÃ© dudas aÃºn tienen.
- Integra la diversidad. Utiliza prompts que incorporen perspectivas de distintas corrientes filosÃ³ficas y autores no hegemÃ³nicos.
- Actualiza tus conocimientos. Las guÃ­as y leyes evolucionan rÃ¡pidamente. Revisa regularmente los marcos normativos y ajusta tus prÃ¡cticas.
- Discute dilemas Ã©ticos. Plantea preguntas como: â€œÂ¿Puede una IA ser moralmente responsable?â€, â€œÂ¿QuÃ© significa comprender?â€, â€œÂ¿Es justo usar sistemas con sesgos en contextos educativos?â€. Estas discusiones fortalecen la formaciÃ³n filosÃ³fica.
  
## ğŸŒ MÃ¡s allÃ¡ del aula
  
La responsabilidad tambiÃ©n implica considerar las consecuencias socioambientales de la IA: el consumo energÃ©tico de entrenar modelos, la explotaciÃ³n laboral en la generaciÃ³n de datos y el impacto en la desigualdad digital. Incluir estos temas en la enseÃ±anza de la filosofÃ­a permite a los estudiantes comprender la interconexiÃ³n entre tecnologÃ­a, Ã©tica y sociedad.

Para profundizar en normas y polÃ­ticas especÃ­ficas, consulta [[Principios Ã‰ticos y Regulaciones de IA]] y [[Historia y Marco Regulatorio]].
  
--- 
[^1]: Los principios de transparencia, privacidad y alternativas humanas provienen del AIÂ BillÂ ofÂ Rights . La Ley de IA de la UE clasifica el uso en educaciÃ³n como de alto riesgo y prohÃ­be prÃ¡cticas manipulativas . La UNESCO subraya la necesidad de un enfoque humanocÃ©ntrico y de verificar la informaciÃ³n generada por IA .