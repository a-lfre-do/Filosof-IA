---
title: Ética y Responsabilidad en IA
parent: Ética
nav_order: 1
---

# 🧪 Ética y Responsabilidad en IA

El uso de **modelos de lenguaje y otras herramientas de IA** en educación no es solo una cuestión técnica: plantea preguntas éticas sobre la autonomía, la veracidad, la equidad y la responsabilidad.  
Esta página sintetiza los principales enfoques y recomendaciones para integrar la IA de forma **responsable y reflexiva** en el aula, con un enfoque prioritario en **Chile y América Latina**.

---

## 🧑‍🎓 Dimensiones éticas

1. **Veracidad y fiabilidad**  
   Los LLM pueden generar respuestas plausibles pero incorrectas (*alucinaciones*). Se recomienda contrastar sus afirmaciones con fuentes confiables y enseñar a los estudiantes a cuestionar críticamente la veracidad de la información que reciben.

2. **Equidad y no discriminación**  
   Los modelos aprenden de datos que pueden contener sesgos. Diseña prompts y actividades que incluyan diversas perspectivas y promueve la reflexión sobre cómo los prejuicios se introducen en la IA. → [[../Fundamentos/Sesgos-Equidad-Justicia.md|Sesgos, Equidad y Justicia en IA]]

3. **Privacidad y consentimiento**  
   No se deben introducir datos personales o sensibles. En Chile aplica la **Ley 19.628 de Protección de la Vida Privada** y su futura actualización (proyecto de ley de datos personales), además de la legislación sectorial en educación. En el contexto latinoamericano, se recomienda alinear el uso de IA con la **Recomendación sobre la Ética de la IA de la UNESCO** y las orientaciones de la CEPAL.

4. **Transparencia**  
   Los estudiantes tienen derecho a saber cuándo se emplea IA y cómo influye en el proceso educativo. Explica siempre la función de la IA y las limitaciones de sus respuestas.

5. **Autonomía y desarrollo del juicio**  
   La IA debe estimular el pensamiento crítico, no sustituirlo. Las tareas deben incentivar que los alumnos elaboren sus propios argumentos y usen la IA como apoyo, no como reemplazo.

---

## 📌 Recomendaciones prácticas

- **Crea un acuerdo de uso**  
  En cada curso, redacta junto con tu clase normas sobre cómo, cuándo y por qué se usará la IA. Incluye cláusulas de consentimiento y uso responsable.

- **Fomenta la reflexión metacognitiva**  
  Tras interactuar con la IA, pide a los estudiantes que identifiquen qué aprendieron, qué errores detectaron y qué dudas aún tienen.

- **Integra la diversidad**  
  Utiliza prompts que incorporen perspectivas de distintas corrientes filosóficas y autores no hegemónicos.  
  Ejemplo: [[../Herramientas/Prompt-Engineering-para-Docentes.md|Prompt Engineering para Docentes]].

- **Actualiza tus conocimientos**  
  Las guías y leyes evolucionan rápidamente. Revisa regularmente los marcos normativos y ajusta tus prácticas.

- **Discute dilemas éticos**  
  Plantea preguntas como:  
  > “¿Puede una IA ser moralmente responsable?”  
  > “¿Qué significa comprender?”  
  > “¿Es justo usar sistemas con sesgos en contextos educativos?”

---

## 🌍 Más allá del aula

La responsabilidad también implica considerar las consecuencias **socioambientales** de la IA:
- Consumo energético del entrenamiento de modelos.
- Condiciones laborales en la generación y etiquetado de datos.
- Impacto en la desigualdad digital.

Incluir estos temas en la enseñanza de la filosofía permite a los estudiantes comprender la **interconexión entre tecnología, ética y sociedad**.

---

## 🔗 Enlaces relacionados

- [[Principios-Eticos-y-Regulaciones.md|Principios Éticos y Regulaciones para el Uso de IA]]
- [[Evaluacion-de-Impacto.md|Evaluación de Impacto en Entornos Educativos]]
- [UNESCO – Recomendación sobre la Ética de la IA](https://unesdoc.unesco.org/ark:/48223/pf0000381137_spa)
- [CEPAL – Gobernanza de la Inteligencia Artificial](https://www.cepal.org/es/publicaciones/48580-gobernanza-la-inteligencia-artificial-america-latina-caribe-desafios-oportunidades)

---
