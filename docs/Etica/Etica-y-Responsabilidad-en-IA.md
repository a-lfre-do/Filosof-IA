---
title: Ã‰tica y Responsabilidad en IA
parent: Ã‰tica
nav_order: 1
---

# ğŸ§ª Ã‰tica y Responsabilidad en IA

El uso de **modelos de lenguaje y otras herramientas de IA** en educaciÃ³n no es solo una cuestiÃ³n tÃ©cnica: plantea preguntas Ã©ticas sobre la autonomÃ­a, la veracidad, la equidad y la responsabilidad.  
Esta pÃ¡gina sintetiza los principales enfoques y recomendaciones para integrar la IA de forma **responsable y reflexiva** en el aula, con un enfoque prioritario en **Chile y AmÃ©rica Latina**.

---

## ğŸ§‘â€ğŸ“ Dimensiones Ã©ticas

1. **Veracidad y fiabilidad**  
   Los LLM pueden generar respuestas plausibles pero incorrectas (*alucinaciones*). Se recomienda contrastar sus afirmaciones con fuentes confiables y enseÃ±ar a los estudiantes a cuestionar crÃ­ticamente la veracidad de la informaciÃ³n que reciben.

2. **Equidad y no discriminaciÃ³n**  
   Los modelos aprenden de datos que pueden contener sesgos. DiseÃ±a prompts y actividades que incluyan diversas perspectivas y promueve la reflexiÃ³n sobre cÃ³mo los prejuicios se introducen en la IA. â†’ [[../Fundamentos/Sesgos-Equidad-Justicia.md|Sesgos, Equidad y Justicia en IA]]

3. **Privacidad y consentimiento**  
   No se deben introducir datos personales o sensibles. En Chile aplica la **Ley 19.628 de ProtecciÃ³n de la Vida Privada** y su futura actualizaciÃ³n (proyecto de ley de datos personales), ademÃ¡s de la legislaciÃ³n sectorial en educaciÃ³n. En el contexto latinoamericano, se recomienda alinear el uso de IA con la **RecomendaciÃ³n sobre la Ã‰tica de la IA de la UNESCO** y las orientaciones de la CEPAL.

4. **Transparencia**  
   Los estudiantes tienen derecho a saber cuÃ¡ndo se emplea IA y cÃ³mo influye en el proceso educativo. Explica siempre la funciÃ³n de la IA y las limitaciones de sus respuestas.

5. **AutonomÃ­a y desarrollo del juicio**  
   La IA debe estimular el pensamiento crÃ­tico, no sustituirlo. Las tareas deben incentivar que los alumnos elaboren sus propios argumentos y usen la IA como apoyo, no como reemplazo.

---

## ğŸ“Œ Recomendaciones prÃ¡cticas

- **Crea un acuerdo de uso**  
  En cada curso, redacta junto con tu clase normas sobre cÃ³mo, cuÃ¡ndo y por quÃ© se usarÃ¡ la IA. Incluye clÃ¡usulas de consentimiento y uso responsable.

- **Fomenta la reflexiÃ³n metacognitiva**  
  Tras interactuar con la IA, pide a los estudiantes que identifiquen quÃ© aprendieron, quÃ© errores detectaron y quÃ© dudas aÃºn tienen.

- **Integra la diversidad**  
  Utiliza prompts que incorporen perspectivas de distintas corrientes filosÃ³ficas y autores no hegemÃ³nicos.  
  Ejemplo: [[../Herramientas/Prompt-Engineering-para-Docentes.md|Prompt Engineering para Docentes]].

- **Actualiza tus conocimientos**  
  Las guÃ­as y leyes evolucionan rÃ¡pidamente. Revisa regularmente los marcos normativos y ajusta tus prÃ¡cticas.

- **Discute dilemas Ã©ticos**  
  Plantea preguntas como:  
  > â€œÂ¿Puede una IA ser moralmente responsable?â€  
  > â€œÂ¿QuÃ© significa comprender?â€  
  > â€œÂ¿Es justo usar sistemas con sesgos en contextos educativos?â€

---

## ğŸŒ MÃ¡s allÃ¡ del aula

La responsabilidad tambiÃ©n implica considerar las consecuencias **socioambientales** de la IA:
- Consumo energÃ©tico del entrenamiento de modelos.
- Condiciones laborales en la generaciÃ³n y etiquetado de datos.
- Impacto en la desigualdad digital.

Incluir estos temas en la enseÃ±anza de la filosofÃ­a permite a los estudiantes comprender la **interconexiÃ³n entre tecnologÃ­a, Ã©tica y sociedad**.

---

## ğŸ”— Enlaces relacionados

- [[Principios-Eticos-y-Regulaciones.md|Principios Ã‰ticos y Regulaciones para el Uso de IA]]
- [[Evaluacion-de-Impacto.md|EvaluaciÃ³n de Impacto en Entornos Educativos]]
- [UNESCO â€“ RecomendaciÃ³n sobre la Ã‰tica de la IA](https://unesdoc.unesco.org/ark:/48223/pf0000381137_spa)
- [CEPAL â€“ Gobernanza de la Inteligencia Artificial](https://www.cepal.org/es/publicaciones/48580-gobernanza-la-inteligencia-artificial-america-latina-caribe-desafios-oportunidades)

---
