# 🧪 Ética y Responsabilidad en IA

El uso de modelos de lenguaje en educación no es solo una cuestión técnica: plantea preguntas éticas sobre la autonomía, la veracidad, la equidad y la responsabilidad. Esta página sintetiza los principales enfoques y recomendaciones para integrar la IA de forma responsable en el aula.
## 🧑‍🎓 Dimensiones éticas

1. Veracidad y fiabilidad. Los LLM pueden generar respuestas plausibles pero incorrectas (alucinaciones). Por ello, se aconseja contrastar sus afirmaciones con fuentes confiables y enseñar a los estudiantes a cuestionar la veracidad de la información que reciben.
2. Equidad y no discriminación. Los modelos aprenden de datos que pueden contener sesgos. Debemos diseñar prompts y actividades que incluyan diversas perspectivas, y promover la reflexión sobre cómo los prejuicios se introducen en la IA.
3. Privacidad y consentimiento. No se deben introducir datos personales o sensibles. Las herramientas utilizadas deben cumplir con marcos legales como el AI Bill of Rights y la Ley de IA de la UE, que exigen limitar la recolección de datos y proporcionar alternativas humanas .
4. Transparencia. Los estudiantes tienen derecho a saber cuándo se emplea IA y cómo influye en el proceso educativo. Explica siempre la función de la IA y las limitaciones de sus respuestas .
5. Autonomía y desarrollo del juicio. La IA debe ser un recurso para estimular el pensamiento crítico, no un sustituto del razonamiento. Las tareas deben incentivar que los alumnos elaboren sus propios argumentos y usen la IA como apoyo.

## 📌 Recomendaciones prácticas

- Crea un acuerdo de uso. En cada curso, redacta con tu clase unas normas sobre cómo, cuándo y por qué se usará la IA. Incluye cláusulas de consentimiento y uso responsable.
- Fomenta la reflexión metacognitiva. Tras interactuar con la IA, pide a los estudiantes que identifiquen qué aprendieron, qué errores detectaron y qué dudas aún tienen.
- Integra la diversidad. Utiliza prompts que incorporen perspectivas de distintas corrientes filosóficas y autores no hegemónicos.
- Actualiza tus conocimientos. Las guías y leyes evolucionan rápidamente. Revisa regularmente los marcos normativos y ajusta tus prácticas.
- Discute dilemas éticos. Plantea preguntas como: “¿Puede una IA ser moralmente responsable?”, “¿Qué significa comprender?”, “¿Es justo usar sistemas con sesgos en contextos educativos?”. Estas discusiones fortalecen la formación filosófica.
  
## 🌍 Más allá del aula
  
La responsabilidad también implica considerar las consecuencias socioambientales de la IA: el consumo energético de entrenar modelos, la explotación laboral en la generación de datos y el impacto en la desigualdad digital. Incluir estos temas en la enseñanza de la filosofía permite a los estudiantes comprender la interconexión entre tecnología, ética y sociedad.

Para profundizar en normas y políticas específicas, consulta [[Principios Éticos y Regulaciones de IA]] y [[Historia y Marco Regulatorio]].
  
--- 
[^1]: Los principios de transparencia, privacidad y alternativas humanas provienen del AI Bill of Rights . La Ley de IA de la UE clasifica el uso en educación como de alto riesgo y prohíbe prácticas manipulativas . La UNESCO subraya la necesidad de un enfoque humanocéntrico y de verificar la información generada por IA .